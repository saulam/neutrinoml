{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVjl-kju6o4S"
   },
   "source": [
    "# Particle identification\n",
    "\n",
    "This assignment aims to learn how to define and run deep-learning methods for particle identification of neutrino events. In the last machine-learning lecture, we implemented a number of classification models using standard machine-learning methods (i.e., logistic regression and decision trees). However, we will use deep learning for this assignment instead, which consists of complex artificial neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UG5VHLK7-iqp"
   },
   "source": [
    "##Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NaUCNuA9DBG5"
   },
   "source": [
    "Let's start with turning on the GPU (if available):\n",
    "\n",
    "```\n",
    "Edit -> Notebook settings -> Hardware accelerator: GPU -> Save.\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHMkB-apwSJy"
   },
   "source": [
    "Download the dataset, as well as load the needed Python packages and modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zeZ5YQbaDkQO",
    "outputId": "3f717198-579d-4d2f-952a-a08945005aa0"
   },
   "outputs": [],
   "source": [
    "!wget \"https://raw.githubusercontent.com/saulam/neutrinoml/main/modules.py\"\n",
    "!wget \"https://raw.githubusercontent.com/saulam/neutrinoml/main/df_pgun_teaching.p\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from modules import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXsuG5BQK8wF"
   },
   "source": [
    "Check whether the GPU was found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6GE94a0PDR1N",
    "outputId": "1d56c023-51de-4425-dcba-4f3c3a2c1332"
   },
   "outputs": [],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVHwIwSOvz3n"
   },
   "source": [
    "##Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sc7lPCGT6o4W"
   },
   "source": [
    "We can now load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GEgXr0CV6o4W"
   },
   "outputs": [],
   "source": [
    "# read dataframe\n",
    "df = pd.read_pickle('df_pgun_teaching.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wSBVlOV-6o4W"
   },
   "source": [
    "We may have a look at the dataset. It consists of 59,578 particle gun events ([from the SFGD detector](https://doi.org/10.1088/1748-0221/15/12/p12003)) with the following attributes:\n",
    "\n",
    "- **TruePID**: PDG code for particle identification (PID); 2212 (proton), 13 (muon), 211 (pion).\n",
    "- **TrueMomentum**: momentum in MeV.\n",
    "- **NNodes**: number of nodes of the event (3D spatial points).\n",
    "- **NodeOrder**: order of the nodes within the event.\n",
    "- **NodePosX**: array with the coordinates of the nodes along the X-axis (in mm).\n",
    "- **NodePosY**: array with the coordinates of the nodes along the Y-axis (in mm).\n",
    "- **NodePosZ**: array with the coordinates of the nodes along the Z-axis (in mm).\n",
    "- **NodeT**: array with the timestamps of the nodes (in ms).\n",
    "- **Nodededx**: array with energy deposits of the nodes (dE/dx).\n",
    "- **TrkLen**: length of the track (in mm).\n",
    "- **TrkEDepo**: total track energy deposition (in arbitrary unit).\n",
    "- **TrkDir1**: track direction, polar angle (in degrees).\n",
    "- **TrkDir2**: track direction, azimuth angle (in degrees).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 847
    },
    "id": "o9FuASKM6o4X",
    "outputId": "c6bebf91-3271-45bd-98a0-73034717d7c8"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RghPKyXA04rQ"
   },
   "source": [
    "And check the correlations of the variables (please notice that the node features are not included since each even has a different length):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "Ag5QkbJKMsVm",
    "outputId": "d8d14870-9467-4bdd-f918-30f370325d68"
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrzNwzscqd4w"
   },
   "source": [
    "The 3D spatial points of the events are usually stored in the form of hits or nodes. We chose the latter for our dataset. A hit corresponds with a cube with real energy deposition (there are usually many hits across the track signature), whilst a node corresponds with a fitted position after performing the track reconstruction.\n",
    "\n",
    "<div>\n",
    "<img src=\"https://raw.githubusercontent.com/saulam/neutrinoml/main/hit.png\" width=\"400\"/>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img src=\"https://raw.githubusercontent.com/saulam/neutrinoml/main/node.png\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5qxEri_6o4X"
   },
   "source": [
    "We may also have a look at the events by plotting the nodes within the detector space. By default, we're looking at the first event (event 0), but we can display more events by playing with the variable `event_number`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "8c9eBj3T6o4Y",
    "outputId": "2d7eb8e6-f380-432c-896a-67de98896082"
   },
   "outputs": [],
   "source": [
    "event_number = 0\n",
    "plot_event(df, event_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g70lBcA36o4Z"
   },
   "source": [
    "Regardless of the type of data we use and the algorithm chosen, it is essential to perform a **preprocessing** of the data, which allows us to prepare the data to make it understandable for the machine-learning algorithm.\n",
    "\n",
    "As explained before, the goal is to learn to predict a label **y** from a fixed-size vector of features **X**. However, the input data is in 3D, and every event (track) has a different size. Thus, a simple way of doing it is to use two of the features to start with: `TrkLen` and `TrkEDepo`. Please, notice that we are encoding the PID code from protons (2212), muons (13), and pions (211) into 0, 1, and 2, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-yfqZYjY6o4Z",
    "outputId": "96f45f27-7e19-473f-e837-73cc8664a2f5"
   },
   "outputs": [],
   "source": [
    "X = np.zeros(shape=(len(df),2), dtype=np.float32) # array of size (n_events, 2)\n",
    "y = np.zeros(shape=(len(df),), dtype=np.float32)  # array of size (n_events,)\n",
    "\n",
    "# fill dataset\n",
    "for event_n, event in df.iterrows():\n",
    "    \n",
    "    pid_label = event['TruePID']\n",
    "    \n",
    "    # retrieve the first node\n",
    "    X[event_n, 0] = event['TrkLen']\n",
    "    X[event_n, 1] = event['TrkEDepo']\n",
    "\n",
    "    # PID label\n",
    "    if pid_label==2212: \n",
    "      pid_label=0 # proton\n",
    "    elif pid_label==13: \n",
    "      pid_label=1 # muons\n",
    "    else:\n",
    "      pid_label=2 # pions\n",
    "    y[event_n] = pid_label\n",
    "\n",
    "# standardize the dataset (mean=0, std=1)\n",
    "X_stan = scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vlvQHUc6o4Z"
   },
   "source": [
    "In order to understand the training data, it's always good to visualise first. For simplicity, let's start comparing protons and muons (ignoring pions). A good way of doing it is to create a scatter plot of one feature against the other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "SDQfji9m6o4a",
    "outputId": "5ab18127-fbcb-4a3d-eaa7-dd011eb8f3b6"
   },
   "outputs": [],
   "source": [
    "param_names = ['TrkLen', 'TrkEDepo']\n",
    "y_names = ['proton', 'muon']\n",
    "\n",
    "plot_params_pid(X[y!=2], y[y!=2], param_names, y_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-INAKi_YAYW"
   },
   "source": [
    "Good! It's easy to distinguish by eye two \"almost\" independent distributions: one for protons and the other for muons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ee4lzVE1yP-m"
   },
   "source": [
    "## Fully connected neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BX5jfc3Q6o4b"
   },
   "source": [
    "Training a machine-learning algorithm is usually not an easy task. The algorithm learns from some training data until it is ready to make predictions on unseen data. In order to test how the algorithm performs on new data, the dataset used for training is divided into two groups (sometimes is divided into three groups, but we're keeping two groups here for simplicity):\n",
    "\n",
    "- Training set: the model learns from this set only. It must be the largest set.\n",
    "- Test set: it is used to evaluate the model at the end of the training, only once it is fully trained. \n",
    "\n",
    "In this example, we keep 60% of the data for training and 40% for testing. Besides, it's always recommended to shuffle the training examples to prevents any bias during the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74sobEvb6o4c"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_stan[y!=2], y[y!=2], test_size=0.4, random_state=7) # random shuffle and split: 60% training, 40% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZoa_hnEWmz2"
   },
   "source": [
    "This assignment aims to deal with deep learning methods, a subset of machine learning consisting of artificial neural networks. We will implement the fully connected neural network (i.e., all neurons in one layer are connected to all the neurons in the next layer) shown below using the Keras interface from the TensorFlow deep-learning framework. Keras is an API ideal for neural-network prototyping. In the architecture below, each neuron must compute the following function $\\sigma(w x + b) < 0.5$, where $w$ and $b$ are the input weight and bias of the neuron, respectively, and $\\sigma$ is the [activation function](https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6).\n",
    "\n",
    "<div>\n",
    "<img src=\"https://raw.githubusercontent.com/saulam/neutrinoml/main/dense_nn.png\" width=\"700\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dswZ3SjYMOKx",
    "outputId": "a7b915af-a75d-4436-b698-bef0768522c7"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(7) # for reproducibility\n",
    "\n",
    "num_features = 2 # TrkLen, TrkEDepo\n",
    "num_classes = 1 # one output unit is enough since it's a binary classification problem\n",
    "\n",
    "# Fully connected neural network model\n",
    "input = Input(shape=(num_features,)) # input layer\n",
    "x = Dense(10, activation='relu')(input) # hidden layer 1\n",
    "x = Dense(10, activation='relu')(x) # hidden layer 2\n",
    "output = Dense(num_classes, activation='sigmoid')(x) # output layer\n",
    "model = Model(inputs=input, outputs=output)\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4xZRB1yhAhc"
   },
   "source": [
    "And train the model for 10 epochs and a batch size of 128:\n",
    "\n",
    "*   Batch: a set of $n$ input examples (also called mini-batch). The input examples in a batch are processed independently, in parallel. During training, a batch results in only one update to the model (one forward pass and one backward pass).\n",
    "*   Epoch: one forward pass and one backward pass of all the training examples. In other words, an epoch is one pass over the entire dataset, and it is used to separate training into distinct phases. For a dataset consisting of $m$ training examples and a batch size of $n$, then it will take $m / n$ iterations to complete one epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79TWw6evN6GU",
    "outputId": "f7aa622d-26ce-47d6-f764-3989409d6365"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rhw-cLdmyAFT"
   },
   "source": [
    "It's also usual to calculate some metrics to evaluate our deep-learning method's performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9etmLMv7co3X",
    "outputId": "37318de4-d348-4da6-a7f1-e2d889a44238"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test).round()\n",
    "print(\"Overall accuracy: {:2.3}\\n\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\" - Proton accuracy: {:2.3}\".format(accuracy_score(y_test[y_test==0], y_pred[y_test==0])))\n",
    "print(\" - Muon accuracy: {:2.3}\\n\".format(accuracy_score(y_test[y_test==1], y_pred[y_test==1])))\n",
    "conf=confusion_matrix(y_pred, y_test)\n",
    "print_conf(conf, ['protons', 'muons'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SODIuuGgyppu"
   },
   "source": [
    "Nice! We're getting almost perfect separation using only two input parameters! With logistic regression (first lecture), proton accuracy was similar, but the muon accuracy it was ~83%. The improvement using neural networks is obvious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFUFjUW36o4g"
   },
   "source": [
    "Is there any room for improving the current results? \n",
    "\n",
    "In the same way we did in the previous lecture, a more robust but straightforward way of making the input data interpretable for the algorithm is to keep the information of only a few nodes of each track. Our preprocessing is illustrated in the following figure (there are many combinations, we are showing just one practical example here):\n",
    "\n",
    "<div>\n",
    "<img src=\"https://raw.githubusercontent.com/saulam/neutrinoml/main/reg.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "where we keep the dE/dx of the first 3 and last 5 nodes of each track, along with their 4 global parameters, building up an array of size 12. For events where the track has less than 8 nodes (first 3 + last 5 nodes), we simply fill the empty positions of the array with -1s.\n",
    "\n",
    "To sum up, with this preprocessing, we should end up having our input dataset **X**, consisting of 59,578 vectors of size 12 each (a 59,578x12 matrix). The values to estimate, **y**, are the labels of each event (proton or muon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x4NZa2hZ6o4g",
    "outputId": "92642595-e99e-46f6-f3b7-e3b4e74bab3f"
   },
   "outputs": [],
   "source": [
    "X = np.zeros(shape=(len(df),12), dtype=np.float32) # array of size (n_event, 12)\n",
    "y = np.zeros(shape=(len(df),), dtype=np.float32)   # array of size (n_event,)\n",
    "X.fill(-1) # filled with -1s\n",
    "\n",
    "# fill dataset\n",
    "for event_n, event in df.iterrows():\n",
    "\n",
    "    NodeOrder = event['NodeOrder']\n",
    "    Nodededx = event['Nodededx'][NodeOrder]\n",
    "\n",
    "    # retrieve up to the first 3 nodes\n",
    "    nfirstnodes = min(Nodededx.shape[0], 3)\n",
    "    X[event_n,:nfirstnodes] = Nodededx[:nfirstnodes]\n",
    "\n",
    "    if Nodededx.shape[0]>nfirstnodes:\n",
    "        # retrieve up to the last 5 nodes\n",
    "        nlastnodes = min(Nodededx.shape[0]-3, 5)\n",
    "        X[event_n,nfirstnodes:nfirstnodes+nlastnodes] = Nodededx[-nlastnodes:]\n",
    "\n",
    "    # global parameters\n",
    "    X[event_n,-4] = event['TrkLen']\n",
    "    X[event_n,-3] = event['TrkEDepo']\n",
    "    X[event_n,-2] = event['TrkDir1']\n",
    "    X[event_n,-1] = event['TrkDir2']\n",
    "\n",
    "    # PID label\n",
    "    pid_label = event['TruePID']\n",
    "    if pid_label==2212:\n",
    "      pid_label=0 # protons\n",
    "    elif pid_label==13: \n",
    "      pid_label=1 # muons\n",
    "    else:\n",
    "      pid_label=2 # pions\n",
    "    y[event_n] = pid_label\n",
    "    y[event_n] = pid_label\n",
    "\n",
    "# standardize the dataset (mean=0, std=1)\n",
    "X_stan = scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qH2A2LAzCsV"
   },
   "source": [
    "In order to understand the training data, it's always good to visualise first. A good way of doing it could be creating a histogram plot of each of our 12 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "id": "bcFeWh3iP7E-",
    "outputId": "11bf124d-bac1-4ba9-951e-2e2312a50453"
   },
   "outputs": [],
   "source": [
    "param_names = ['dE/dx node 1', 'dE/dx node 2', 'dE/dx node 3', 'dE/dx node n-4',\\\n",
    "               'dE/dx node n-3', 'dE/dx node n-2', 'dE/dx node n-1', 'dE/dx node n', 'TrkLen',\\\n",
    "               'TrkEDepo', 'TrkDir1', 'TrkDir2']\n",
    "y_names = [\"proton\", \"muon\",\"pion\"]\n",
    "plot_parameters(X, y, param_names, y_names, mode=\"classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YePGg59gzOwH"
   },
   "source": [
    "We split the dataset again into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2EIkyVK-vwLR"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_stan[y!=2], y[y!=2], test_size=0.4, random_state=7) # 60% training and 40% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hecj03Q5zXTi"
   },
   "source": [
    "Define a new network (we just need to fix the input layer), train it on the new dataset and test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Z30XFUvRAJC",
    "outputId": "74a61f62-ee0c-466d-bf60-0567232cbc3b"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(7) # for reproducibility\n",
    "\n",
    "num_features = 12 # TrkLen, TrkEDepo\n",
    "num_classes = 1 # one output unit is enough since it's a binary classification problem\n",
    "\n",
    "# Fully connected neural network model\n",
    "input = Input(shape=(num_features,)) # input layer\n",
    "x = Dense(10, activation='relu')(input) # hidden layer 1\n",
    "x = Dense(10, activation='relu')(x) # hidden layer 2\n",
    "output = Dense(num_classes, activation='sigmoid')(x) # output layer\n",
    "model = Model(inputs=input, outputs=output)\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=128, verbose=1)\n",
    "\n",
    "# test the model\n",
    "y_pred = model.predict(X_test).round()\n",
    "print(\"Overall accuracy: {:2.3}\\n\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\" - Proton accuracy: {:2.3}\".format(accuracy_score(y_test[y_test==0], y_pred[y_test==0])))\n",
    "print(\" - Muon accuracy: {:2.3}\\n\".format(accuracy_score(y_test[y_test==1], y_pred[y_test==1])))\n",
    "conf=confusion_matrix(y_pred, y_test)\n",
    "print_conf(conf, ['protons', 'muons'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LjXwKJZAzz9R"
   },
   "source": [
    "The results are amazing! However, we have solved a binary classification problem, while our dataset has a third type of particles that we have ignored (pions). Out network architecture is easily extensible to solve problems with a number of classes $k>2$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6GEOENi9TEeY"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_stan, y, test_size=0.4, random_state=7) # 60% training and 40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zRlHNKF_TG_g",
    "outputId": "1fcf11ef-6a02-4238-a05f-20b04e9fb5dd"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(7) # for reproducibility\n",
    "\n",
    "num_features = 12 # TrkLen, TrkEDepo\n",
    "num_classes = 3 # proton, muon, and pion\n",
    "\n",
    "# Fully connected neural network model\n",
    "input = Input(shape=(num_features,)) # input layer\n",
    "x = Dense(10, activation='relu')(input) # hidden layer 1\n",
    "x = Dense(10, activation='relu')(x) # hidden layer 2\n",
    "output = Dense(num_classes, activation='softmax')(x) # output layer\n",
    "model = Model(inputs=input, outputs=output)\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=128, verbose=1)\n",
    "\n",
    "# test the model\n",
    "y_pred = model.predict(X_test).argmax(axis=1)\n",
    "print(\"Overall accuracy: {:2.3}\\n\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\" - Proton accuracy: {:2.3}\".format(accuracy_score(y_test[y_test==0], y_pred[y_test==0])))\n",
    "print(\" - Muon accuracy: {:2.3}\".format(accuracy_score(y_test[y_test==1], y_pred[y_test==1])))\n",
    "print(\" - Pion accuracy: {:2.3}\\n\".format(accuracy_score(y_test[y_test==2], y_pred[y_test==2])))\n",
    "conf=confusion_matrix(y_pred, y_test)\n",
    "print_conf(conf, ['protons', 'muons', 'pions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ek-qpcnGmR2N"
   },
   "source": [
    "The muon/pion separation looks much better than for decision trees (last lecture)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MM52HRfbncU_"
   },
   "source": [
    "The way to add more capacity to our model (making it more capable to learn) is to add more layers and neurons per layer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0slZOIEmlor",
    "outputId": "149fc82d-641a-49cf-c4c4-80ab87eb437c"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(7) # for reproducibility\n",
    "\n",
    "num_features = 12 # TrkLen, TrkEDepo\n",
    "num_classes = 3 # proton, muon, and pion\n",
    "\n",
    "# Fully connected neural network model\n",
    "input = Input(shape=(num_features,)) # input layer\n",
    "x = Dense(100, activation='relu')(input) # hidden layer 1\n",
    "x = Dense(100, activation='relu')(x) # hidden layer 2\n",
    "x = Dense(100, activation='relu')(x) # hidden layer 2\n",
    "x = Dense(100, activation='relu')(x) # hidden layer 2\n",
    "output = Dense(num_classes, activation='softmax')(x) # output layer\n",
    "model = Model(inputs=input, outputs=output)\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=128, verbose=1)\n",
    "\n",
    "# test the model\n",
    "y_pred = model.predict(X_test).argmax(axis=1)\n",
    "print(\"Overall accuracy: {:2.3}\\n\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\" - Proton accuracy: {:2.3}\".format(accuracy_score(y_test[y_test==0], y_pred[y_test==0])))\n",
    "print(\" - Muon accuracy: {:2.3}\".format(accuracy_score(y_test[y_test==1], y_pred[y_test==1])))\n",
    "print(\" - Pion accuracy: {:2.3}\\n\".format(accuracy_score(y_test[y_test==2], y_pred[y_test==2])))\n",
    "conf=confusion_matrix(y_pred, y_test)\n",
    "print_conf(conf, ['protons', 'muons', 'pions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McWnT5jTysUa"
   },
   "source": [
    "## Convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVOpKD9eDg78"
   },
   "source": [
    "[Convolutional neural network (CNN)](https://direct.mit.edu/neco/article-abstract/1/4/541/5515/Backpropagation-Applied-to-Handwritten-Zip-Code?redirectedFrom=fulltext) algorithms that operate on images have been very successful in a number of [HEP tasks](https://iml-wg.github.io/HEPML-LivingReview/). The main feature of CNNs is that they apply a series of filters (using convolutions, hence the name of the CNN), usually followed by spatial pooling, applied in sequence to extract increasingly powerful and abstract features that allow the CNN to classify the images [[citation](http://dl.acm.org/citation.cfm?id=2999134.2999257)]. Each of the filters consists of a set of values that are learnt by the CNN through the training process.  CNNs are typically deep neural networks that consist of many convolutional layers, with the output from one convolutional layer forming the input to the next. The last layers of a CNN are usually fully connected layers, where the output layer is followed by a sigmoid or softmax activation function.\n",
    "\n",
    "Since CNNs learn from images, let's generate a 2D image for each event in the dataset. An easy way of doing it is to save the YZ projection of each 3D event (the projection chosen is not completely arbitrary. We wanted to keep the Z-axis since it corresponds to the beam direction):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lm_EAPlaUhTx"
   },
   "outputs": [],
   "source": [
    "def map_value(y,z):\n",
    "  min_y = -257.56\n",
    "  max_y = 317.56\n",
    "  min_z = -2888.78\n",
    "  max_z = -999.1\n",
    "\n",
    "  y = int((y-min_y)//10)\n",
    "  z = int((z-min_z)//10)\n",
    "\n",
    "  return y, z\n",
    "\n",
    "\n",
    "X = np.zeros(shape=(len(df),58,189,1), dtype=np.float32) # array of size (n_event, 56, 184)\n",
    "y = np.zeros(shape=(len(df),), dtype=np.float32)   # array of size (n_event,)\n",
    "\n",
    "# fill dataset\n",
    "for event_n, event in df.iterrows():\n",
    "\n",
    "    NodePosY = event['NodePosY']\n",
    "    NodePosZ = event['NodePosZ']\n",
    "    Nodededx = event['Nodededx']\n",
    "\n",
    "    old_y, old_z, dedxs = -1, -1, []\n",
    "    for index in range(len(NodePosY)):\n",
    "        y_coord, z_coord = NodePosY[index], NodePosZ[index]\n",
    "        y_coord, z_coord = map_value(y_coord, z_coord)\n",
    "\n",
    "        if index==0 or (y_coord==old_y and z_coord==old_z):\n",
    "            dedxs.append(Nodededx[index])\n",
    "            old_y, old_z = y_coord, z_coord\n",
    "        else:\n",
    "            X[event_n, old_y, old_z, 0] = np.mean(dedxs)\n",
    "            old_y, old_z, dedxs = y_coord, z_coord, []\n",
    "            dedxs.append(Nodededx[index])\n",
    "\n",
    "    X[event_n, old_y, old_z, 0] = np.mean(dedxs)\n",
    "\n",
    "    # PID label\n",
    "    pid_label = event['TruePID']\n",
    "    if pid_label==2212:\n",
    "      pid_label=0 # protons\n",
    "    elif pid_label==13: \n",
    "      pid_label=1 # muons\n",
    "    else:\n",
    "      pid_label=2 # pions\n",
    "    y[event_n] = pid_label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=7) # 60% training and 40% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnOBphBcjy1D"
   },
   "source": [
    "We may plot two different views of the same 3D event and the corresponding YZ projection to check everything worked as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "id": "1k7W_ne8fvWJ",
    "outputId": "958f1aa9-047e-4bab-9a35-078b5609998e"
   },
   "outputs": [],
   "source": [
    "event_number = 0\n",
    "plot_projection(df, event_number, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EcFELvFxj0a"
   },
   "source": [
    "We will implement the following convolutional connected neural network:\n",
    "\n",
    "<div>\n",
    "<img src=\"https://raw.githubusercontent.com/saulam/neutrinoml/main/cnn.png\" width=\"900\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QApgnODzX5EQ",
    "outputId": "870a18a0-3156-4383-ba0d-4ebbf6a2db57"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(7) # for reproducibility\n",
    "\n",
    "# Convolutional neural network model\n",
    "inp_shape = (58,189,1)\n",
    "input = Input(shape=inp_shape) # input layer\n",
    "x = Conv2D(16, (6,18), padding='valid', strides=(2,3), activation='relu')(input) # conv layer 1\n",
    "x = MaxPooling2D(pool_size=(2,3), strides=(2,3))(x) # max-pooling 1\n",
    "x = Conv2D(32, (3,3), padding='valid', strides=(2,3), activation='relu')(x) # conv layer 2\n",
    "x = MaxPooling2D(pool_size=(2,3), strides=(2,3))(x) # max-pooling 2\n",
    "x = Flatten()(x) # from 3D to 1D\n",
    "x = Dense(64, activation='relu')(x) # fully connected layer at the end\n",
    "output = Dense(3, activation='softmax')(x) # output layer\n",
    "\n",
    "# compile the model\n",
    "model = Model(inputs=input, outputs=output)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BHuTPTVWladz",
    "outputId": "9c8e97a8-ade3-4681-cac2-76fb18a094b1"
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=128, verbose=1)\n",
    "\n",
    "# test the model\n",
    "y_pred = model.predict(X_test).argmax(axis=1)\n",
    "print(\"Overall accuracy: {:2.3}\\n\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\" - Proton accuracy: {:2.3}\".format(accuracy_score(y_test[y_test==0], y_pred[y_test==0])))\n",
    "print(\" - Muon accuracy: {:2.3}\".format(accuracy_score(y_test[y_test==1], y_pred[y_test==1])))\n",
    "print(\" - Pion accuracy: {:2.3}\\n\".format(accuracy_score(y_test[y_test==2], y_pred[y_test==2])))\n",
    "conf=confusion_matrix(y_pred, y_test)\n",
    "print_conf(conf, ['protons', 'muons', 'pions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VEiG_FQk2YM"
   },
   "source": [
    "How do we interpret the results? Does it mean CNNs are less powerful than fully connected networks (FCNs)? No! From the physics point of view, we are training the CNN to identify particles but just looking at their signatures in a 2D projection! In contrast, we were giving our FCN as input some reconstructed physics parameters that were useful for performing PID. Thus, the scientist's goal should be to understand which method is best for each situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1vfmgtEIKdw"
   },
   "source": [
    "##Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2BF4oRRITXC"
   },
   "source": [
    "It's your time to beat the results above!\n",
    "\n",
    "The idea is to add capacity to the models by designing wider (more neurons or convolutional filters per layer) and deeper (more layers) networks.\n",
    "\n",
    "Useful links:\n",
    "\n",
    "- How to Control Neural Network Model Capacity With Nodes and Layers: https://machinelearningmastery.com/how-to-control-neural-network-model-capacity-with-nodes-and-layers/.\n",
    "- TensorFlow 2 quickstart for beginners: https://www.tensorflow.org/tutorials/quickstart/beginner.\n",
    "- Building a Convolutional Neural Network Using TensorFlow â€“ Keras: https://www.analyticsvidhya.com/blog/2021/06/building-a-convolutional-neural-network-using-tensorflow-keras/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8DX25P_WIovR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of neural_nets.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
